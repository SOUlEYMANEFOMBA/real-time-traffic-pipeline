services:
#    zookeeper:
#       image: confluentinc/cp-zookeeper:7.4.0
#       hostname: zookeeper
#       container_name: zookeeper_container
#       ports:
#       - "2181:2181"
#       environment:
#          ZOOKEEPER_CLIENT_PORT: 2181
#          ZOOKEEPER_TICK_TIME: 2000
#       healthcheck:
#          test: ['CMD', 'bash', '-c', "echo 'ruok' | nc localhost 2181"]
#          interval: 10s
#          timeout: 5s
#          retries: 5
#       networks:
#       - confluent

#    broker:
#       image: confluentinc/cp-server:7.4.0
#       hostname: broker
#       container_name: broker_contenaire
#       depends_on:
#          zookeeper:
#            condition: service_healthy
#       ports:
#       - "9092:9092"
#       - "9101:9101"
#       - "29092:29092"
#       environment:
#          KAFKA_BROKER_ID: 1
#          KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
#          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
#          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
#          KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
#          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#          KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
#          KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
#          KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
#          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
#          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
#          KAFKA_JMX_PORT: 9101
#          KAFKA_JMX_HOSTNAME: localhost
#          KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
#          CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
#          CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
#          CONFLUENT_METRICS_ENABLE: 'false'
#          CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
#       networks:
#       - confluent
#       healthcheck:
#          test: ["CMD", "bash", "-c", 'nc -z localhost 9092']
#          interval: 10s
#          timeout: 5s
#          retries: 5

#    schema-registry:
#       image: confluentinc/cp-schema-registry:7.4.0
#       hostname: schema-registry
#       container_name: schema_registry_container
#       depends_on:
#          broker:
#            condition: service_healthy
#       ports:
#       - "8081:8081"
#       environment:
#          SCHEMA_REGISTRY_HOST_NAME: schema-registry
#          SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
#          SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
#       networks:
#       - confluent
#       healthcheck:
#          test: ["CMD", "curl", "-f", "http://localhost:8081/"]
#          interval: 30s
#          timeout: 10s
#          retries: 5

#    control-center:
#       image: confluentinc/cp-enterprise-control-center:7.4.0
#       hostname: control-center
#       container_name: control_center_container
#       depends_on:
#          broker:
#             condition: service_healthy
#          schema-registry:
#             condition: service_healthy
#       ports:
#       - "9021:9021"
#       environment:
#          CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
#          CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
#          CONTROL_CENTER_REPLICATION_FACTOR: 1
#          CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
#          CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
#          CONFLUENT_METRICS_TOPIC_REPLICATION: 1
#          CONFLUENT_METRICS_ENABLE: 'false'
#          PORT: 9021
#       networks:
#       - confluent
#       healthcheck:
#          test: ["CMD", "curl", "-f", "http://localhost:9021/health"]
#          interval: 30s
#          timeout: 10s
#          retries: 5
   
   webserver:
      build: 
         context: .
         dockerfile: Dockerfile
      container_name: airflow_webserver
      depends_on:
         - postgres
      environment:
         - LOAD_EX=n
         - EXECUTOR=Sequential
         - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
         - AIRFLOW_WEBSERVER_SECRET_KEY=this_is_a_very_secured_key
      logging:
         options:
            max-size: 10m
            max-file: "3"
      volumes:
         - ../Dags:/opt/airflow/dags
         - ../airflow-data/includes:/opt/airflow/includes
         - ../airflow-data/logs:/opt/airflow/logs
         - ../airflow-data/plugins:/opt/airflow/plugins
         - ../airflow-data/airflow.cfg:/opt/airflow/airflow.cfg
      ports:
         - "8082:8080"
      command: bash -c "/opt/airflow/init_airflow.sh && airflow webserver"
      healthcheck:
         test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
         interval: 30s
         timeout: 10s
         retries: 5
      networks:
         - confluent

   scheduler:
      build: 
         context: .
         dockerfile: Dockerfile
      container_name: airflow_scheduler
      depends_on:
         webserver:
            condition: service_healthy
      volumes:
         - ../dags:/opt/airflow/dags
         - ../airflow-data/includes:/opt/airflow/includes
         - ../airflow-data/logs:/opt/airflow/logs
         - ../airflow-data/plugins:/opt/airflow/plugins
         - ../airflow-data/airflow.cfg:/opt/airflow/airflow.cfg
      environment:
         - LOAD_EX=n
         - EXECUTOR=Sequential
         - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
         - AIRFLOW_WEBSERVER_SECRET_KEY=this_is_a_very_secured_key
      command: bash -c "airflow db upgrade && airflow scheduler"
      networks:
         - confluent

   postgres:
      image: postgres:14.0
      container_name: airflow_postgres
      environment:
         - POSTGRES_USER=airflow
         - POSTGRES_PASSWORD=airflow
         - POSTGRES_DB=airflow
      logging:
         options:
            max-size: 10m
            max-file: "3"
      networks:
         - confluent

   spark-master:
      build :
         context : ./spark
         dockerfile: Dockerfile
      container_name: spark_master_container
      volumes:
      - ..:/workspace
      environment:
         JAVA_HOME: /usr/lib/jvm/java-11-openjdk-amd64
      command: /opt/bitnami/spark/bin/spark-class org.apache.spark.deploy.master.Master
      ports:
         - "9090:9090"
         - "7077:7077"
      networks:
         - confluent
   spark-worker:
      build :
         context : ./spark
         dockerfile: Dockerfile
      container_name: spark_worker_container
      command: /opt/bitnami/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
      depends_on:
         - spark-master
      environment:
         JAVA_HOME: /usr/lib/jvm/java-11-openjdk-amd64 
         SPARK_MODE: worker
         SPARK_WORKER_CORES: 2
         SPARK_WORKER_MEMORY: 1g
         SPARK_MASTER_URL: spark://spark-master:7077
      networks:
         - confluent
   # cassandra_db:
   #    image: cassandra:latest
   #    container_name: cassandra_container
   #    hostname: cassandra
   #    ports:
   #       - "9042:9042"
   #    environment:
   #       - MAX_HEAP_SIZE=512M
   #       - HEAP_NEWSIZE=100M
   #       - CASSANDRA_USERNAME=cassandra
   #       - CASSANDRA_PASSWORD=cassandra
   #    networks:
   #       - confluent
networks:
   confluent:
